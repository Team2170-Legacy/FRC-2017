// RobotBuilder Version: 2.0
//
// This file was generated by RobotBuilder. It contains sections of
// code that are automatically generated and assigned by robotbuilder.
// These sections will be updated in the future when you export to
// C++ from RobotBuilder. Do not put any code or make any change in
// the blocks indicating autogenerated code or it will be lost on an
// update. Deleting the comments indicating the section will prevent
// it from being updated in the future.
#include "vision/GearTwoNEW.h"
#include "Robot.h"
#include "WPiLib.h"
#include <vector>
#include <unistd.h>

// BEGIN AUTOGENERATED CODE, SOURCE=ROBOTBUILDER ID=INITIALIZATION
std::shared_ptr<DriveTrain> Robot::driveTrain;
std::unique_ptr<OI> Robot::oi;

    // END AUTOGENERATED CODE, SOURCE=ROBOTBUILDER ID=INITIALIZATION

int Gear_x;		// Global Gear Target x-location (in 320x240 image coordinates)
int e_Gear_x;	// Global variable for error in Gear_x location

void Robot::VisionThread() {
	int status = 1;
	int* status_ptr = &status;

	//	cs::SetCameraExposureHoldCurrent(0, status_ptr);
	//	usleep(1000000);
		//cs::SetCameraExposureManual(0, 2, status_ptr);
		//usleep(1000000);

		//cs::SetCameraBrightness(0, 2, status_ptr);

//	cs::SetCameraExposureManual(0, 10, status_ptr);
//	usleep(1000000);
	cs::UsbCamera camera = CameraServer::GetInstance()->StartAutomaticCapture(0);
//	camera.SetResolution(640, 480);
	camera.SetResolution(320, 240);
	camera.SetExposureManual(20);
	usleep(1000000);

//	cs::SetCameraExposureManual(0, 10, status_ptr);
//	camera.SetCameraExposureManual(0, 10, status_ptr);

	cs::CvSink cvSink = CameraServer::GetInstance()->GetVideo();
	//cs::CvSource outputStreamStd = CameraServer::GetInstance()->PutVideo("Cam0", 640, 480);
	cs::CvSource outputStreamStd = CameraServer::GetInstance()->PutVideo("Cam0", 320, 240);

//	cs::SetCameraExposureManual(0, 10, status_ptr);

//	CS_Source our_cam_device = cs::CreateUsbCameraDev("Cam0", 0, status_ptr);
//	cs::SetCameraExposureManual(our_cam_device, 10, status_ptr);

//	usleep(5000000);
//	cs::SetSourceFPS(0, 30, status_ptr);


	cv::Mat source;
	cv::Mat output;

	// MK 2/4/8:26pm
	grip::GearTwoNEW GearPipeline;

	// MK 2/4/8:26pm

	cv::Rect r1, r2;

	std::vector<std::vector<cv::Point> >* contours_ptr;
	std::vector<std::vector<cv::Point> > contours;
	std::vector<cv::Point> contour1;
	std::vector<cv::Point> contour2;


	while(true) {
	//while(false) {
//		cs::SetCameraExposureManual(0, 10, status_ptr);

		cvSink.GrabFrame(source);

		// MK 2/4 8:26pm
		GearPipeline.Process(source);
		//	GearPipeline.Process(GearInput);

		contours_ptr = GearPipeline.GetFilterContoursOutput();
		contours = *contours_ptr;

//		cvtColor(source, output, cv::COLOR_BGR2RGB);
		output = source;

		if (!contours.empty())
		{
			contour1 = contours[0];
			contour2 = contours[1];
			//r = cv::boundingRect(GearPipeline.GetFindContoursOutput()[0]);	DOESN'T WORK!!!
			r1 = cv::boundingRect(contour1);
			r2 = cv::boundingRect(contour2);
			cv::Point tl1 = r1.tl();	//Rect_::x and Rect_::y
			cv::Point br1 = r1.br();
			cv::Point tl2 = r2.tl();	//Rect_::x and Rect_::y
			cv::Point br2 = r2.br();

			cv::Scalar color = cv::Scalar(180,105,255); // BGR for hot pink color
			cv::rectangle(output, tl1, br1, color, 4, 8, 0);
			cv::rectangle(output, tl2, br2, color, 4, 8, 0);

			int midpt_r1 [2] = {(tl1.x + br1.x) / 2, (tl1.y + br1.y) / 2};
			int midpt_r2 [2] = {(tl2.x + br2.x) / 2, (tl2.y + br2.y) / 2};
			int gear [2] = {(midpt_r1 [0] + midpt_r2 [0]) / 2, (midpt_r1 [1] + midpt_r2 [1]) / 2};

			cv::Point gear_midpoint( gear[0], gear[1]);
			cv::line(output, gear_midpoint, gear_midpoint, color, 4);

			Gear_x = gear[0];			// Transfer Gear Target x-location to other threads & Robot command functions
			e_Gear_x = Gear_x - 160;	// Define error in Gear_x location

//			std::cout << "Midpoint of Rectangle 1: (" << midpt_r1 [0] << "," << midpt_r1 [1] << ")" << std::endl;
//			std::cout << "Midpoint of Rectangle 2: (" << midpt_r2 [0] << "," << midpt_r2 [1] << ")" << std::endl;
//			std::cout << "Gear Location: (" << gear [0] << "," << gear [1] << ")" << std::endl;

			//cv::Point r1tl = cv::Point(100, 100);
			//cv::Point r1br = cv::Point(400, 400);
			//cv::rectangle(output, r1tl, r1br, color, 4, 8, 0);
			//cv::rectangle(source, r2.tl(), r2.br(), color, 4, 8, 0);

		} // if (!contours.empty())
		outputStreamStd.PutFrame(output);
	} // while(true)
}; //void Robot::VisionThread()

void Robot::VisionThreadBBoiler() {
	int status = 1;
	int* status_ptr = &status;

	//	cs::SetCameraExposureHoldCurrent(0, status_ptr);
	//	usleep(1000000);
		//cs::SetCameraExposureManual(0, 2, status_ptr);
		//usleep(1000000);

		//cs::SetCameraBrightness(0, 2, status_ptr);

//	cs::SetCameraExposureManual(0, 10, status_ptr);
//	usleep(1000000);
	cs::UsbCamera camera2 = CameraServer::GetInstance()->StartAutomaticCapture(1);
//	camera.SetResolution(640, 480);
	camera2.SetResolution(320, 240);
	//camera.SetBrightness(50);

	usleep(1000000);

//	cs::SetCameraExposureManual(0, 10, status_ptr);
//	camera.SetCameraExposureManual(0, 10, status_ptr);

	cs::CvSink cvSink = CameraServer::GetInstance()->GetVideo();
	//cs::CvSource outputStreamStd = CameraServer::GetInstance()->PutVideo("Cam0", 640, 480);
	camera2.SetExposureManual(100);
	cs::CvSource outputStreamStd2 = CameraServer::GetInstance()->PutVideo("Cam1", 320, 240);

//	cs::SetCameraExposureManual(0, 10, status_ptr);

//	CS_Source our_cam_device = cs::CreateUsbCameraDev("Cam0", 0, status_ptr);
//	cs::SetCameraExposureManual(our_cam_device, 10, status_ptr);

//	usleep(5000000);
//	cs::SetSourceFPS(0, 30, status_ptr);


	cv::Mat source;
	cv::Mat output;

	grip::BBoilerPipeline BBoilerPipeline;

	cv::Rect r1, r8;

	std::vector<std::vector<cv::Point> >* contours_ptr;
	std::vector<std::vector<cv::Point> > contours;
	std::vector<cv::Point> contour1;
	std::vector<cv::Point> contour8;


	while(true) {
	//while(false) {
//		cs::SetCameraExposureManual(0, 10, status_ptr);

		cvSink.GrabFrame(source);

		// MK 2/4 8:26pm
		BBoilerPipeline.Process(source);
		//	GearPipeline.Process(GearInput);

		contours_ptr = BBoilerPipeline.GetFilterContoursOutput();
		contours = *contours_ptr;

//		cvtColor(source, output, cv::COLOR_BGR2RGB);
		output = source;

		if (!contours.empty())
		{
			contour1 = contours[0];
			contour8 = contours[7];
			//r = cv::boundingRect(GearPipeline.GetFindContoursOutput()[0]);	DOESN'T WORK!!!
			r1 = cv::boundingRect(contour1);
			r8 = cv::boundingRect(contour8);
			cv::Point tl1 = r1.tl();	//Rect_::x and Rect_::y
			cv::Point br1 = r1.br();
			cv::Point tl8 = r8.tl();	//Rect_::x and Rect_::y
			cv::Point br8 = r8.br();

			cv::Scalar color2 = cv::Scalar(255,255,0); // BGR for cyan
			cv::rectangle(output, tl1, br1, color2, 4, 8, 0);
			cv::rectangle(output, tl8, br8, color2, 4, 8, 0);

			int midpt_r1 [2] = {(tl1.x + br1.x) / 2, (tl1.y + br1.y) / 2};
			int midpt_r2 [2] = {(tl8.x + br8.x) / 2, (tl8.y + br8.y) / 2};
			int gear [2] = {(midpt_r1 [0] + midpt_r2 [0]) / 2, (midpt_r1 [1] + midpt_r2 [1]) / 2};

			cv::Point BBoiler_midpoint( gear[0], gear[1]);
			cv::line(output, BBoiler_midpoint, BBoiler_midpoint, color2, 4);

			Gear_x = gear[0];			// Transfer Gear Target x-location to other threads & Robot command functions
			e_Gear_x = Gear_x - 160;	// Define error in Gear_x location

//			std::cout << "Midpoint of Rectangle 1: (" << midpt_r1 [0] << "," << midpt_r1 [1] << ")" << std::endl;
//			std::cout << "Midpoint of Rectangle 2: (" << midpt_r2 [0] << "," << midpt_r2 [1] << ")" << std::endl;
//			std::cout << "Gear Location: (" << gear [0] << "," << gear [1] << ")" << std::endl;

			//cv::Point r1tl = cv::Point(100, 100);
			//cv::Point r1br = cv::Point(400, 400);
			//cv::rectangle(output, r1tl, r1br, color, 4, 8, 0);
			//cv::rectangle(source, r2.tl(), r2.br(), color, 4, 8, 0);

		} // if (!contours.empty())
		outputStreamStd2.PutFrame(output);
	} // while(true)
}; //void Robot::VisionThread()

void Robot::RobotInit() {
	RobotMap::init();


//	cs::UsbCamera camera = CameraServer::GetInstance()->StartAutomaticCapture();
//	camera.SetResolution(640, 480);
//	GearCameraSink = CameraServer::GetInstance()->GetVideo();
//	cs::CvSource outputStreamStd = CameraServer::GetInstance()->PutVideo("Cam0", 640, 480);
//	cv::Mat GearInput;
//	cv::Mat Filtered;
//	cv::Rect r1, r2;
//	GearCameraSink.GrabFrame(GearInput);
//	cv::cvtColor(GearInput, Filtered, cv::COLOR_BGR2GRAY);
//	outputStreamStd.PutFrame(Filtered);
//	GearPipeline.Process(GearInput);

//	int status = 1;
//	int* status_ptr = &status;
//
//	cs::SetCameraExposureManual(0, 10, status_ptr);
//	usleep(1000000);

	std::thread visionThread(VisionThread);
	visionThread.detach();

	std::thread visionThreadBBoiler(VisionThreadBBoiler);
	visionThreadBBoiler.detach();

	//cs::CvSource outputStreamStd = CameraServer::GetInstance()->PutVideo("Gear1", 640, 480);

	//table = NetworkTable::GetTable("ContourReport");

	// BEGIN AUTOGENERATED CODE, SOURCE=ROBOTBUILDER ID=CONSTRUCTORS
    driveTrain.reset(new DriveTrain());

    // END AUTOGENERATED CODE, SOURCE=ROBOTBUILDER ID=CONSTRUCTORS
	// This MUST be here. If the OI creates Commands (which it very likely
	// will), constructing it during the construction of CommandBase (from
	// which commands extend), subsystems are not guaranteed to be
	// yet. Thus, their requires() statements may grab null pointers. Bad
	// news. Don't move it.
	oi.reset(new OI());

	// instantiate the command used for the autonomous period
	// BEGIN AUTOGENERATED CODE, SOURCE=ROBOTBUILDER ID=AUTONOMOUS
	autonomousCommand.reset(new AutonomousCommand());

    // END AUTOGENERATED CODE, SOURCE=ROBOTBUILDER ID=AUTONOMOUS


  }

/**
 * This function is called when the disabled button is hit.
 * You can use it to reset subsystems before shutting down.
 */
void Robot::DisabledInit(){

}

void Robot::DisabledPeriodic() {
	Scheduler::GetInstance()->Run();
}

void Robot::AutonomousInit() {
	if (autonomousCommand.get() != nullptr)
		autonomousCommand->Start();
}

void Robot::AutonomousPeriodic() {
	Scheduler::GetInstance()->Run();
}

void Robot::TeleopInit() {
	// This makes sure that the autonomous stops running when
	// teleop starts running. If you want the autonomous to
	// continue until interrupted by another command, remove
	// these lines or comment it out.
	if (autonomousCommand.get() != nullptr)
		autonomousCommand->Cancel();
}

void Robot::TeleopPeriodic() {
//	cv::Mat GearInput;
//	cv::Rect r1, r2;
//	GearCameraSink.GrabFrame(GearInput);
//	GearPipeline.Process(GearInput);
//	//cs::CvSource outputStreamStd = CameraServer::GetInstance()->PutVideo("Gear1", 640, 480);

//	cv::Mat GearInput;
//	cv::Rect r1, r2;

//	std::vector<std::vector<cv::Point> >* contours_ptr;
//	std::vector<std::vector<cv::Point> > contours;
//	std::vector<cv::Point> contour1;
//	std::vector<cv::Point> contour2;

//	contours_ptr = GearPipeline.GetFindContoursOutput();
//	contours = *contours_ptr;

	// MK 2/4/8:26pm
//	std::cout << "Checking if contours empty..." << std::endl;
//
//	if (!contours.empty())
//	{
//		contour1 = contours[0];
//		contour2 = contours[1];
//		//r = cv::boundingRect(GearPipeline.GetFindContoursOutput()[0]);	DOESN'T WORK!!!
//		r1 = cv::boundingRect(contour1);
//		r2 = cv::boundingRect(contour2);
//		cv::Point tl1 = r1.tl();	//Rect_::x and Rect_::y
//		cv::Point br1 = r1.br();
//		cv::Point tl2 = r2.tl();	//Rect_::x and Rect_::y
//		cv::Point br2 = r2.br();
//
//		double r1w = r1.width;
//		double r2w = r2.width;
////		double r1h = r1.height;
////		double r2h = r2.height;
//
//		std::cout << "Rectangle 1: tl = " << tl1.x << "\t" << tl1.y << std::endl;
//		std::cout << "Rectangle 1: br = " << br1.x << "\t" << br1.y << std::endl;
//		std::cout << "Rectangle 1: x = " << r1.x << "\t" << "y = "<< r1.y << std::endl;
//
//		std::cout << "Rectangle 2: tl = " << tl2.x << "\t" << tl2.y << std::endl;
//		std::cout << "Rectangle 2: br = " << br2.x << "\t" << br2.y << std::endl;
//		std::cout << "Rectangle 2: x = " << r2.x << "\t" << "y = "<< r2.y << std::endl;
//
//		std::cout << "Rectangle 1 Width: " << r1w << std::endl;
//		std::cout << "Rectangle 2 Width: " << r2w << std::endl;
//
//		int midpt_r1 [2] = {(tl1.x + br1.x) / 2, (tl1.y + br1.y) / 2};
//		int midpt_r2 [2] = {(tl2.x + br2.x) / 2, (tl2.y + br2.y) / 2};
//		int gear [2] = {(midpt_r1 [0] + midpt_r2 [0]) / 2, (midpt_r1 [1] + midpt_r2 [1]) / 2};
//
////		double midpt_r1x = (tl1.x + br1.x) / 2;
////		double midpt_r1y = (tl1.y + br1.y) / 2;
////		double midpt_r2x = (tl2.x + br2.x) / 2;
////		double midpt_r2y = (tl2.y + br2.y) / 2;
//
//		std::cout << "Midpoint of Rectangle 1: (" << midpt_r1 [0] << "," << midpt_r1 [1] << ")" << std::endl;
//		std::cout << "Midpoint of Rectangle 2: (" << midpt_r2 [0] << "," << midpt_r2 [1] << ")" << std::endl;
//		std::cout << "Gear Location: (" << gear [0] << "," << gear [1] << ")" << std::endl;
//
//		cv::Scalar color = cv::Scalar(180,105,255); // BGR for hot pink color
//
		//cv::Mat img = GearCameraSink;
		// Create rectangles around the two retro-reflective pieces of tape
		// cv::Rect
		//cv::rectangle(img, r1.tl(), r1.br(), color, 1, 8, 0);
		//cv::rectangle(img, r2.tl(), r2.br(), color, 1, 8, 0);

		//outputStreamStd.PutFrame(img);
		//outputStreamStd.PutFrame(img);
	//}
	//Results = GearPipeline.getfilterContoursOutput();

	std::cout << "Gear x-Location = " << Gear_x << std::endl;
	std::cout << "Gear x-Location Error = " << e_Gear_x << std::endl;

	SmartDashboard::PutNumber("Error for Gear_x: ", e_Gear_x);

	Scheduler::GetInstance()->Run();

}

void Robot::TestPeriodic() {
	lw->Run();
}

START_ROBOT_CLASS(Robot);

